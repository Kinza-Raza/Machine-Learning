{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infrastructure that mimics the brain \n",
    "\n",
    "### Artificial Neural Networks (ANN) are multi-layer fully-connected neural nets that look like the figure below. They consist of an input layer, multiple hidden layers, and an output layer. Every node in one layer is connected to every other node in the next layer. We make the network deeper by increasing the number of hidden layers.\n",
    "\n",
    "### multiple neurons/node form the network. the neurons get the input data.\n",
    "\n",
    "![title](capture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input values are independent variables. But they are only for one row. For eg, person 1's age, salary, job etc.\n",
    "\n",
    "## We must standardize/normalize the input values so that the neural network can process it easily\n",
    "\n",
    "### Each input has different weights, which are crucial in neural network as it learns from it. we have to adjust them to make sure what factor is considered to what extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In ANN:\n",
    "\n",
    "### Step 1: Add weights of all inputs\n",
    "\n",
    "### Step 2: Apply activation function to weighted sums \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Activation Function:\n",
    " \n",
    "##### Their main purpose is to convert a input signal of a node in a A-NN to an output signal. That output signal now is used as a input in the next layer in the stack.\n",
    "\n",
    " # Why use activation function: \n",
    " \n",
    "##### If we do not apply a Activation function then the output signal would simply be a simple linear function.A linear function is just a polynomial of one degree. Now, a linear equation is easy to solve but they are limited in their complexity and have less power to learn complex functional mappings from data.\n",
    "##### A Neural Network without Activation function would simply be a Linear regression Model, which has limited power and does not performs good most of the times. We want our Neural Network to not just learn and compute a linear function but something more complicated than that. Also without activation function our Neural network would not be able to learn and model other complicated kinds of data such as images, videos , audio , speech etc. \n",
    "##### That is why we use Artificial Neural network techniques such as Deep learning to make sense of something complicated ,high dimensional,non-linear -big datasets, where the model has lots and lots of hidden layers in between and has a very complicated architecture which helps us to make sense and extract knowledge form such complicated big datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of activation function: \n",
    "\n",
    "### 1) Threshold Function:\n",
    "\n",
    "If value is less than 0, output is passed as 0. If value greater than 0, value of output passed as 1. \n",
    "\n",
    "![title](capture2.png)\n",
    "\n",
    "### 2) Sigmoid:\n",
    "\n",
    "aka logistic. (same formula as logistic regression). gradual smooth curve. useful in the final layer when predicting probabilities.\n",
    "\n",
    "![title](capture3.png)\n",
    "\n",
    "### 3) Rectifier:\n",
    "\n",
    "progresses gradually above values greater than 1. most used function.\n",
    "\n",
    "![title](capture4.png)\n",
    "\n",
    "### 3) Hyperbolic Tangent:\n",
    "\n",
    "y-axis/output gives values in negative as well. \n",
    "\n",
    "![title](capture5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do Neural networks work? \n",
    "\n",
    "If dataset given of real estate, with multiple factors such as\n",
    "\n",
    "- age (how old is the property)\n",
    "- distance from city\n",
    "- bedrooms\n",
    "- area\n",
    "- porch/garage etc.\n",
    "\n",
    "in the neural network, multiple nodes present. Each node takes different sets of inputs and performs activation function on it.\n",
    "the calculations of each node is combined to give the final output which would be the price of the property\n",
    "\n",
    "![title](capture6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do neural networks learn?\n",
    "\n",
    "for any one row the available input data is fed into the node, and it gives an expected value of y 'y-cap'. It's compared with the original value, 'y' and cost function is calculated.\n",
    "\n",
    "cost function = ![title](capture7.png)\n",
    "\n",
    "Aim is to decrease the cost function so the y-cap is closer to the real value of y. data fed back into the node so weights of inputs are adjusted and process repeated once again using same data (of particular row) and this is repeated until ycap approx. equal to y\n",
    "\n",
    "![title](capture8.png)\n",
    "\n",
    "usually neural networks working on multiple rows to be trained better, so above process takes place simultaneously for each row. and combined cost function calculated.\n",
    "\n",
    "when cost function is minimum, it means weights have been adjusted and optimal value of y-cap found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent: \n",
    "\n",
    "### To minimize the cost function we can:\n",
    "\n",
    "1) apply brute force and just choose random weights and repeat to obtain minimum cost function.\n",
    "\n",
    "- problem: when we increase number of weights, curse of dimensionality. \n",
    "\n",
    "2) Gradient Descent\n",
    "\n",
    "- we check gradient at any specific point on this curve. if slope is negative curve is going downhill. so we calculate slope until we reach the minimum point of curve where gradient is equal to 0.\n",
    "\n",
    "![title](capture9.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run one row at a time and adjust weights. then proceed to another row and repeat until all rows have been fed into the neural network.\n",
    "\n",
    "\n",
    "![title](capture10.png)\n",
    "\n",
    "\n",
    "## Stochastic gradient descent is faster than batch gradient descent as it doesn't load data of all rows simultaneously. it helps in finding the global minimum point of the curve rather than the local minimum points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation is an advanced algorithm in which all the weights are adjusted simultaneously. The errors are fed back to the neural network in backward direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to train ANN with Stochastic gradient descent: \n",
    "\n",
    "![title](capture11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
